{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuBdK2qVQq-2",
        "outputId": "8ac04f06-2692-4171-8009-8a53ff4d7093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULcfXyzZRjfq",
        "outputId": "6223eb2d-8ed1-4839-f5b3-ca5ffe7fedd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#define N 100\n",
        "using namespace std;\n",
        "\n",
        "// DEVICE: Kernel para multiplicación de matrices\n",
        "__global__ void matrixMultiplicationKernel(float* A, float* B, float* C, int n) {\n",
        "    // Índices del hilo en la matriz resultado\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // Índice de fila\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // Índice de columna\n",
        "\n",
        "    // Asegurarse de que los índices estén dentro de los límites\n",
        "    if (row < n && col < n) {\n",
        "        float value = 0.0;\n",
        "\n",
        "        // Cálculo del producto escalar para la celda (row, col)\n",
        "        for (int k = 0; k < n; ++k) {\n",
        "            value += A[row * n + k] * B[k * n + col];\n",
        "        }\n",
        "\n",
        "        // Almacena el valor calculado en la matriz resultado\n",
        "        C[row * n + col] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// HOST\n",
        "int main() {\n",
        "    int matrixSize = N * N * sizeof(float); // Tamaño total de una matriz\n",
        "\n",
        "    // Reservar memoria para las matrices en el host\n",
        "    float* A = new float[N * N];\n",
        "    float* B = new float[N * N];\n",
        "    float* C = new float[N * N]; // Resultado\n",
        "\n",
        "    // Inicializar las matrices A y B en el host\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            A[i * N + j] = i + j;       // Elementos de A\n",
        "            B[i * N + j] = i - j;       // Elementos de B\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Reservar memoria en la GPU para las matrices\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, matrixSize);\n",
        "    cudaMalloc((void**)&d_B, matrixSize);\n",
        "    cudaMalloc((void**)&d_C, matrixSize);\n",
        "\n",
        "    // Copiar las matrices A y B del host al device\n",
        "    cudaMemcpy(d_A, A, matrixSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, matrixSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configuración de bloques e hilos\n",
        "    dim3 threadsPerBlock(16, 16); // 16x16 hilos por bloque\n",
        "    dim3 numBlocks((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Llamada al kernel\n",
        "    matrixMultiplicationKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Sincronizar la GPU\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copiar el resultado de la GPU al host\n",
        "    cudaMemcpy(C, d_C, matrixSize, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Mostrar una parte de la matriz resultado\n",
        "    cout << \"Matriz Resultado (primeros 10x10 elementos):\" << endl;\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        for (int j = 0; j < 10; ++j) {\n",
        "            cout << C[i * N + j] << \"\\t\";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "\n",
        "    // Liberar memoria en el device\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    // Liberar memoria en el host\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xHKarXbUr2e",
        "outputId": "903ac753-4e3a-4c05-c187-d5d6762bb4e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz Resultado (primeros 10x10 elementos):\n",
            "328350\t323400\t318450\t313500\t308550\t303600\t298650\t293700\t288750\t283800\t\n",
            "333300\t328250\t323200\t318150\t313100\t308050\t303000\t297950\t292900\t287850\t\n",
            "338250\t333100\t327950\t322800\t317650\t312500\t307350\t302200\t297050\t291900\t\n",
            "343200\t337950\t332700\t327450\t322200\t316950\t311700\t306450\t301200\t295950\t\n",
            "348150\t342800\t337450\t332100\t326750\t321400\t316050\t310700\t305350\t300000\t\n",
            "353100\t347650\t342200\t336750\t331300\t325850\t320400\t314950\t309500\t304050\t\n",
            "358050\t352500\t346950\t341400\t335850\t330300\t324750\t319200\t313650\t308100\t\n",
            "363000\t357350\t351700\t346050\t340400\t334750\t329100\t323450\t317800\t312150\t\n",
            "367950\t362200\t356450\t350700\t344950\t339200\t333450\t327700\t321950\t316200\t\n",
            "372900\t367050\t361200\t355350\t349500\t343650\t337800\t331950\t326100\t320250\t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}